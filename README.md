# @playwright-ai/auto-debug

ğŸ¤– Automatic Playwright test debugging with AI assistance

[![npm version](https://img.shields.io/npm/v/playwright-ai-auto-debug.svg)](https://www.npmjs.com/package/playwright-ai-auto-debug)

<!-- ## ğŸ¥ Demo Video

[![Demo Video](https://img.youtube.com/vi/mva6ktpKOKw/maxresdefault.jpg)](https://youtu.be/mva6ktpKOKw) -->

Watch the demo to see how the library automatically analyzes Playwright test errors and provides AI-powered solutions integrated directly into your HTML reports.

## ğŸ“¦ Installation

```bash
npm install @playwright-ai/auto-debug
```

## ğŸ”§ Configuration

### Configuration via ai.conf.js (recommended)

Create an `ai.conf.js` file in your project root:

```javascript
// ai.conf.js
export const ai_conf = {
  // Required parameters
  api_key: 'your_api_key_here',
  
  // Optional parameters
  ai_server: 'https://api.mistral.ai',        // AI server URL
  model: 'mistral-medium',                    // AI model
  results_dir: 'test-results',                // Test results folder
  max_prompt_length: 2000,                    // Maximum prompt length
  request_delay: 1000,                        // Delay between requests (ms)
  
  // Custom AI messages (optional)
  messages: [
    {
      role: 'system',
      content: 'You are an AI assistant for debugging Playwright tests. Analyze errors and suggest specific solutions in English. Be concise and to the point.'
    },
    // You can add additional system messages
    {
      role: 'system', 
      content: 'When analyzing errors, consider our project specifics: we use React, TypeScript and test e-commerce functionality.'
    }
  ]
};
```

Your `playwright.config.js` or `playwright.config.ts` remains clean:

```javascript
import { defineConfig } from '@playwright/test';

export default defineConfig({
  // Regular Playwright settings
  testDir: './tests',
  reporter: 'html',
  // No ai_conf here - it's in ai.conf.js
});
```

### TypeScript Support

For TypeScript projects, you can create `ai.conf.ts` with full type safety:

```typescript
// ai.conf.ts
import type { AiConfig } from 'playwright-ai-auto-debug';

export const ai_conf: AiConfig = {
  api_key: process.env.API_KEY || 'your_api_key_here',
  ai_server: 'https://api.mistral.ai',
  model: 'mistral-medium',
  results_dir: 'test-results',
  report_dir: 'playwright-report',
  max_prompt_length: 2000,
  request_delay: 1000,
  error_file_patterns: [
    'copy-prompt.txt',
    'error-context.md',
    'error.txt',
    'test-error.md',
    '*-error.txt',
    '*-error.md'
  ],
  messages: [
    {
      role: 'system',
      content: 'Ğ¢Ñ‹ AI Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰Ğ½Ğ¸Ğº Ğ¿Ğ¾ Ğ¾Ñ‚Ğ»Ğ°Ğ´ĞºĞµ Playwright Ñ‚ĞµÑÑ‚Ğ¾Ğ². ĞĞ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒĞ¹ Ğ¾ÑˆĞ¸Ğ±ĞºĞ¸ Ğ¸ Ğ¿Ñ€ĞµĞ´Ğ»Ğ°Ğ³Ğ°Ğ¹ ĞºĞ¾Ğ½ĞºÑ€ĞµÑ‚Ğ½Ñ‹Ğµ Ñ€ĞµÑˆĞµĞ½Ğ¸Ñ.'
    }
  ]
};
```

**ĞĞ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğµ Ğ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ğµ ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ğ¸:**
- Ğ•ÑĞ»Ğ¸ ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒĞµÑ‚ `ai.conf.ts` - Ğ·Ğ°Ğ³Ñ€ÑƒĞ¶Ğ°ĞµÑ‚ÑÑ TypeScript ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ñ
- Ğ•ÑĞ»Ğ¸ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ `ai.conf.js` - Ğ·Ğ°Ğ³Ñ€ÑƒĞ¶Ğ°ĞµÑ‚ÑÑ JavaScript ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ñ
- TypeScript ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ñ Ğ¸Ğ¼ĞµĞµÑ‚ Ğ¿Ñ€Ğ¸Ğ¾Ñ€Ğ¸Ñ‚ĞµÑ‚ Ğ½Ğ°Ğ´ JavaScript

> âš ï¸ **Ğ’Ğ°Ğ¶Ğ½Ğ¾**: `tsx` ÑƒĞ¶Ğµ Ğ²ĞºĞ»ÑÑ‡ĞµĞ½ Ğ² Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚Ğ¸ Ğ¿Ğ°ĞºĞµÑ‚Ğ°, Ğ´Ğ¾Ğ¿Ğ¾Ğ»Ğ½Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ°Ñ ÑƒÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞ° Ğ½Ğµ Ñ‚Ñ€ĞµĞ±ÑƒĞµÑ‚ÑÑ.

### Alternative configuration via .env

Create a `.env` file in the project root:

```env
API_KEY=your_api_key_here
```

> âš ï¸ When using configuration via `ai.conf.js` or `ai.conf.ts`, settings from `.env` are ignored

## ğŸš€ Usage

### CLI command

```bash
npx playwright-ai
```

### Via npm scripts

Add to `package.json`:

```json
{
  "scripts": {
    "debug:ai": "npx playwright-ai"
  }
}
```

Then run:

```bash
npm run debug:ai
```

## âš™ï¸ Configuration Parameters

| Parameter | Type | Required | Default | Description |
|-----------|------|----------|---------|-------------|
| `api_key` | string | âœ… | - | API key for AI service |
| `ai_server` | string | âŒ | `https://api.mistral.ai` | AI server URL |
| `model` | string | âŒ | `mistral-medium` | AI model for analysis |
| `results_dir` | string | âŒ | `test-results` | Test results folder |
| `report_dir` | string | âŒ | `playwright-report` | HTML reports folder |
| `max_prompt_length` | number | âŒ | `2000` | Maximum prompt length |
| `request_delay` | number | âŒ | `2000` | Delay between requests (ms) |
| `error_file_patterns` | array | âŒ | See below | Error file patterns |
| `save_ai_responses` | boolean | âŒ | `false` | Save AI responses to Markdown |
| `ai_responses_dir` | string | âŒ | `ai-responses` | Directory for AI responses |
| `allure_integration` | boolean | âŒ | `false` | Enable Allure integration |
| `allure_results_dir` | string | âŒ | `allure-results` | Allure results directory |
| `messages` | array | âŒ | System message | Custom AI messages |

### HTML Reports Search

The library automatically searches for HTML reports in the following locations (in priority order):

1. `playwright-report/index.html` - standard Playwright location
2. `index.html` - in project root  
3. `test-results/index.html` - in results folder
4. In the same folder as the error file
5. In the parent folder of the error file
6. Alternative names: `report.html`, `test-report.html`

You can configure the reports folder via the `report_dir` parameter:

```javascript
ai_conf: {
  api_key: 'your_key',
  report_dir: 'my-custom-reports',  // Will search in my-custom-reports/index.html
  results_dir: 'test-results'
}
```

### Supported Error Files

By default, the library searches for the following file types:

- `copy-prompt.txt` - standard Playwright file
- `error-context.md` - alternative format with error context
- `error.txt` - simple text file with error
- `test-error.md` - Markdown file with error description
- `*-error.txt` - any files ending with `-error.txt`
- `*-error.md` - any files ending with `-error.md`

You can configure custom patterns via the `error_file_patterns` parameter:

```javascript
ai_conf: {
  api_key: 'your_key',
  error_file_patterns: [
    'my-custom-error.txt',
    'failure-*.md',
    'test-results.json'
  ]
}
```

## ğŸ” How It Works

1. **Load Configuration**: Reads settings from `ai.conf.js` or `ai.conf.ts`
2. **Find Errors**: Automatically finds all `copy-prompt.txt` files in the specified folder
3. **AI Analysis**: Sends error content to AI for solutions
4. **Update Reports**: Adds error and solution block to Playwright HTML reports

## ğŸ“‹ Example Result

After running the command, a stylish block integrated with Playwright design will appear in your HTML reports:

```html
<div class="ai-debug-section">
  <h2 class="ai-debug-header">ğŸ¤– AI Debug Assistant</h2>
  <div class="ai-debug-content">
    <div class="ai-error-section">
      <div class="ai-section-title">âŒ Detected Error</div>
      <div class="ai-error-details">Error: Timeout while waiting for selector...</div>
    </div>
    <div class="ai-solution-section">
      <div class="ai-section-title ai-solution-title">ğŸ’¡ Recommended Solution</div>
      <div class="ai-solution-content">
        <p>Try adding a wait before this step...</p>
      </div>
    </div>
  </div>
</div>
```

### ğŸ¨ Design Features

- **Playwright Integration**: Block uses the same styles and color scheme as standard reports
- **Responsive**: Automatically adapts to screen size
- **Code Formatting**: Markdown support, code highlighting in backticks
- **Readability**: Clear separation of error and solution with color coding
- **Modern Design**: Gradients, shadows and rounded corners in Playwright style

## ğŸ“Š Execution Logs

The tool provides detailed real-time output during processing:

```bash
ğŸš€ Starting automatic Playwright test debugging...

âš™ï¸  Loading AI configuration...
ğŸ“‹ Loading JavaScript configuration...
âœ… AI configuration loaded from ai.conf.js

ğŸ” Searching for error files...
ğŸ“„ Found HTML report: test-results/index.html
âœ… Found error file: test-results/copy-prompt.txt
ğŸ“‹ Found 1 error file(s)

ğŸ“ Processing 1/1: test-results/copy-prompt.txt
ğŸ“Š Content length: 398 chars
ğŸ¯ Using model: mistral-medium
ğŸ” Sent to AI...
ğŸ¤– AI Response:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
The error indicates that Playwright couldn't find the login button...
[Real-time streaming of AI response continues here]
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
âœ… Response received (1714 chars)
ğŸ“„ Updating HTML report: test-results/index.html
âœ… Successfully processed file 1/1

ğŸ“Š Processing Summary:
   âœ… Successfully processed: 1/1

âœ… Debugging completed successfully!
```

### ğŸ–¥ï¸ Real-time Features

- **Live AI Streaming**: See AI responses as they are generated in real-time
- **Processing Details**: Content length, model information, file paths
- **Visual Separators**: Clear formatting with lines and emojis
- **Progress Tracking**: File-by-file processing status
- **Response Metrics**: Character count and processing time information

## ğŸ“Š Allure Integration

The library provides seamless and invisible integration with Allure reports - AI responses are automatically attached to failed tests without creating additional test results.

### How It Works

```mermaid
graph TD
    A["ğŸ§ª Playwright Tests"] --> B["âŒ Failed Tests"]
    A --> C["âœ… Passed Tests"]
    
    B --> D["ğŸ“„ Error Files<br/>copy-prompt.txt<br/>checkout-error.txt"]
    
    D --> E["ğŸ¤– AI Analysis"]
    E --> F["ğŸ’¡ AI Solutions<br/>- Login timeout fix<br/>- Checkout selector fix"]
    
    F --> G["ğŸ“ Smart Test Matching"]
    G --> H["ğŸ¯ Keyword Scoring<br/>Match errors to tests"]
    
    H --> I["ğŸ”— Attach to Failed Tests"]
    I --> J["ğŸ“Š Allure Report"]
    J --> K["ğŸ¤– AI Debug Analysis<br/>attached only to failed tests"]
    
    C --> L["No AI Analysis<br/>for passed tests"]
    
    style B fill:#ffe6e6
    style C fill:#e6ffe6
    style E fill:#e6f3ff
    style G fill:#fff9e6
    style K fill:#fff2e6
```

### Enable Allure Integration

Add to your `ai.conf.js` or `ai.conf.ts`:

```javascript
export const ai_conf = {
  api_key: 'your_api_key',
  allure_integration: true,
  allure_results_dir: 'allure-results',
  // ... other settings
};
```

### Playwright Configuration

Configure Playwright to use Allure reporter in `playwright.config.js`:

```javascript
import { defineConfig } from '@playwright/test';

export default defineConfig({
  reporter: [
    ['html'],
    ['allure-playwright', {
      detail: true,
      outputFolder: 'allure-results',
      suiteTitle: false
    }]
  ],
  // ... other settings
});
```

### Generate Allure Report

After running tests and AI analysis:

```bash
# Run your tests
npx playwright test

# Run AI analysis
npx playwright-ai

# Generate Allure report
npx allure generate allure-results -o allure-report

# Open report
npx allure open allure-report
```

### What Gets Added to Failed Tests

- ğŸ¤– **AI Debug Analysis Attachment**: Markdown file with AI solution attached to the failed test
- ğŸ·ï¸ **Smart Label**: `ai-analyzed: true` label for filtering (doesn't affect report structure)
- ğŸ“‹ **Rich Content**: Original error details, stack traces, and AI recommendations in readable format
- ğŸ¯ **Smart Matching**: Intelligent algorithm matches error files to the most relevant failed tests
- ğŸš« **No Duplicates**: Prevents multiple AI attachments for the same test

### Allure Report Features

- ğŸ“ **Seamless Attachments**: AI analysis appears as a natural part of failed test results
- ğŸ” **Smart Filtering**: Filter tests with AI analysis using the `ai-analyzed` label
- ğŸ“Š **No Clutter**: Report structure remains clean and professional
- ğŸ¤– **Rich Analysis**: Detailed AI recommendations right where you need them
- ğŸ¯ **Precise Targeting**: Only failed tests with actual errors get AI analysis
- ğŸ“‹ **Structured Content**: Well-formatted Markdown with error details and solutions

### Example Integration

When a test fails, you'll see:
- Original test failure information
- Screenshots and traces (if configured)
- **ğŸ¤– AI Debug Analysis** attachment with solution

The AI attachment contains:
```markdown
# ğŸ¤– AI Debug Analysis

**Test:** Login should work with valid credentials
**Status:** failed
**Generated:** 15.01.2024, 14:30:25

## ğŸ” Error Details
```
[Original error details]
```

## ğŸ’¡ AI Solution
[AI recommendations and solutions]
```

## âš™ï¸ Requirements

- Node.js >= 16.0.0
- API key for AI service
- Playwright tests with generated reports
- `ai.conf.js` or `ai.conf.ts` file with AI configuration

## ğŸ”’ Security

- API key is stored in project configuration
- Add `ai.conf.js` or `ai.conf.ts` to `.gitignore` if using private keys
- Rate limiting is respected for API requests

## ğŸ› Troubleshooting

### Rate Limiting (429 Error)
If you encounter "Too Many Requests" errors:

```javascript
ai_conf: {
  api_key: 'your_key',
  request_delay: 3000,  // Increase delay between requests
  // ... other settings
}
```

**Solutions:**
- Increase `request_delay` (try 3000-5000ms)
- Process fewer files at once
- Wait before retrying
- Check your API plan limits

### Authentication Errors (401/403)
- Verify your API key is correct
- Check API key permissions
- Ensure sufficient credits/quota

### Network Issues
- Check internet connection
- Verify AI server URL
- Try again later if server is unavailable

## ğŸ“„ License

MIT 